#!/bin/bash

# moves the output csv files from /software/mrblackburn/pymol into /home/mrblackburn/results
# also deletes un-needed files generated by pymol

if [ ! -e Results ]; then
	mkdir Results
fi

echo "Cleaning up /software and gathering result files..."


## Move to top of directory
cd /

declare -i numCIF=0
numCIF=$(find software/mrblackburn/pymol -maxdepth 1 -type f -name "*.cif" | wc -l)

declare -i numCSV=0
numCSV=$(find software/mrblackburn/pymol -maxdepth 1 -type f -name "*.csv" | wc -l)

if [ $numCIF -gt 0 ]; then
	rm software/mrblackburn/pymol/*.cif       # added an if branch to check if -!e *cif, then rm *cif
fi

if [ $numCSV -gt 0 ]; then

	for filename in home/mrblackburn/output/*.out; do
	
		# extract the original PDB ID from the output filename, then convert it to uppercase
		name=$(basename -s ".out" " $filename" | sed 's/SASA_//g' | sed -E 's/_([0-9]+)//g' )
		name=$(echo ${name^^})

		## implement a 'find' command substition that pulls csv files with names that contain the value of 'name'
		mv $(find software/mrblackburn/pymol -maxdepth 1 -type f -name "*$name*") home/mrblackburn/Results

	done

	# TODO : and gets its basename (ie., the job's name, or fetched query), and using the basename to pull corresponding *csv. from
	# TODO : /software/mrblackburn/pymol/ will return only *.csv files that correspond to finished SASA calculation output files.
	# TODO : this will be helpful specifically for collecting finished jobs while others are still running; also, for finding which IDs
	# TODO : keep getting stuck on hold or run forever because of their image size (simply create a list of the 'problem-sized' jobs after these are collected.

	echo "Done. Directory contents shown below:"
fi

## return to my directory and call 'checkstuff.sh' to see directory contents and the job queue
cd /home/mrblackburn
./checkstuff.sh
